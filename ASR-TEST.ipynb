{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-jqXKfG_k34"
   },
   "source": [
    "# Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JGdPj2BiCPBv",
    "outputId": "91d3fdde-ba9c-47cf-f99a-c4055d71e2e0"
   },
   "outputs": [],
   "source": [
    "!pip install pyctcdecode\n",
    "!pip install https://github.com/kpu/kenlm/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3w0ws8FTsxHP",
    "outputId": "a912b9ba-4196-4468-d115-18a8cabc348f"
   },
   "outputs": [],
   "source": [
    "!pip install vosk\n",
    "!wget https://alphacephei.com/vosk/models/vosk-model-small-ru-0.22.zip\n",
    "!unzip vosk-model-small-ru-0.22.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZjWNlFE7xuMC",
    "outputId": "46dede20-e4b9-492c-a15a-d5824e37ce19"
   },
   "outputs": [],
   "source": [
    "!wget https://alphacephei.com/vosk/models/vosk-model-ru-0.42.zip\n",
    "!unzip vosk-model-ru-0.42.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DlHQ_uYhtRLc",
    "outputId": "f6df8eff-7831-4592-a894-5e0b6a6c4f4e"
   },
   "outputs": [],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0O0InXxzuTK9",
    "outputId": "69c6f2e5-a600-4a91-8b51-b757243c93ac"
   },
   "outputs": [],
   "source": [
    "!pip install audioread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "xCvZ9Nkp-Mkt",
    "outputId": "8db398b4-e35c-4d88-a0a5-bbe1276d6d72"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import requests\n",
    "import time\n",
    "import tqdm\n",
    "import torch\n",
    "from scipy.signal import resample\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import wave\n",
    "import json\n",
    "from pydub import AudioSegment\n",
    "import audioread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "PcfOQKgHW3_y"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "_xF0h4ag-mrG"
   },
   "outputs": [],
   "source": [
    "format = '.flac'\n",
    "path_to_data = ''\n",
    "labels_file = path_to_data + 'text.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "NV9psd6Q-0Ln"
   },
   "outputs": [],
   "source": [
    "labels = pd.read_excel(labels_file)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "AdzrMFmQAPh8"
   },
   "outputs": [],
   "source": [
    "class audio_data:\n",
    "    def __init__(self, data_frame, path_to_data, format):\n",
    "        self.data_frame = data_frame\n",
    "        self.path_to_data = path_to_data\n",
    "        self.format = format\n",
    "        self.asr_systems = {}\n",
    "\n",
    "    def get_file_path(self, index):\n",
    "        return self.path_to_data + self.data_frame.iloc[index]['name'] + self.format\n",
    "\n",
    "    def get_file_text_label(self, index):\n",
    "        return self.data_frame.iloc[index]['label']\n",
    "\n",
    "    def get_audio_file(self, index):\n",
    "        return librosa.load(\n",
    "            self.get_file_path(index),\n",
    "            sr=None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "w8NphCLVAesk"
   },
   "outputs": [],
   "source": [
    "data = audio_data(labels, path_to_data, format)\n",
    "data.get_file_path(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "O9TNRz94_JU0"
   },
   "outputs": [],
   "source": [
    "ipd.Audio(data.get_file_path(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npdfTTz6ua_O"
   },
   "source": [
    "# Audio Data Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "iYFwPJNtuagM"
   },
   "outputs": [],
   "source": [
    "length = 0\n",
    "\n",
    "for i in range(len(data.data_frame)):\n",
    "    with audioread.audio_open(data.get_file_path(i)) as f:\n",
    "        length += f.duration\n",
    "length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDpYxrO8DPHV"
   },
   "source": [
    "# Speech Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "I2gI_quzQQxj"
   },
   "outputs": [],
   "source": [
    "file_id = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "2r2hu6ykBgLJ"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "API_KEY_ID = \"\"\n",
    "API_KEY_SECRET = \"\"\n",
    "LANG = \"ru\"\n",
    "\n",
    "FILE_PATH = data.get_file_path(file_id)\n",
    "\n",
    "# The translation result type.\n",
    "# 1, the default result type, the json format for sentences and words with begin time and end time.\n",
    "# 2, the json format for the generated subtitles with begin time and end time.\n",
    "# 3, the srt format for the generated subtitles with begin time and end time.\n",
    "# 4, the plain text format for transcription results without begin time and end time.\n",
    "RESULT_TYPE = 4\n",
    "\n",
    "headers = {\"keyId\": API_KEY_ID, \"keySecret\": API_KEY_SECRET}\n",
    "\n",
    "\n",
    "def create(path_to_file):\n",
    "    create_data = {\n",
    "        \"lang\": LANG,\n",
    "    }\n",
    "    files = {}\n",
    "    create_url = \"https://api.speechflow.io/asr/file/v1/create\"\n",
    "\n",
    "    create_url += \"?lang=\" + LANG\n",
    "    files['file'] = open(path_to_file, \"rb\")\n",
    "    response = requests.post(create_url, headers=headers, files=files)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        create_result = response.json()\n",
    "        if create_result[\"code\"] == 10000:\n",
    "            task_id = create_result[\"taskId\"]\n",
    "        else:\n",
    "            print(\"create error:\")\n",
    "            print(create_result[\"msg\"])\n",
    "            task_id = \"\"\n",
    "    else:\n",
    "        print('create request failed: ', response.status_code)\n",
    "        task_id = \"\"\n",
    "    return task_id\n",
    "\n",
    "\n",
    "def query(task_id):\n",
    "    query_url = \"https://api.speechflow.io/asr/file/v1/query?taskId=\" + task_id + \"&resultType=\" + str(RESULT_TYPE)\n",
    "    while (True):\n",
    "        response = requests.get(query_url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            query_result = response.json()\n",
    "            if query_result[\"code\"] == 11000:\n",
    "                return query_result[\"result\"]\n",
    "                break\n",
    "            elif query_result[\"code\"] == 11001:\n",
    "                time.sleep(3)\n",
    "                continue\n",
    "            else:\n",
    "                print(\"query error:\")\n",
    "                print(query_result[\"msg\"])\n",
    "                break\n",
    "\n",
    "\n",
    "def speech_flow_transcribe(path_to_file):\n",
    "    task_id = create(path_to_file)\n",
    "    if (task_id != \"\"):\n",
    "        return query(task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Lh0IXFYpBsBu"
   },
   "outputs": [],
   "source": [
    "res = speech_flow_transcribe(FILE_PATH)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ULH9cYJrw3AO"
   },
   "outputs": [],
   "source": [
    "df = data.data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "K4h9zqWoQAet"
   },
   "outputs": [],
   "source": [
    "transcriptions = list()\n",
    "\n",
    "for index, row in tqdm.tqdm(df.iterrows(), total=len(df)):\n",
    "    transcription = speech_flow_transcribe(data.get_file_path(index))\n",
    "    transcriptions.append(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "-GkNitI4xvoD"
   },
   "outputs": [],
   "source": [
    "transcriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-C395b2T38Nh"
   },
   "source": [
    "# SaluteSpeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "EzKYqSaM2jQ-"
   },
   "outputs": [],
   "source": [
    "url = \"https://ngw.devices.sberbank.ru:9443/api/v2/oauth\"\n",
    "\n",
    "payload={\n",
    "  'scope': 'SALUTE_SPEECH_PERS'\n",
    "}\n",
    "headers = {\n",
    "  'Content-Type': 'application/x-www-form-urlencoded',\n",
    "  'Accept': 'application/json',\n",
    "  'RqUID': '',\n",
    "  'Authorization': 'Basic '\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload, verify=False);\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "FB8PWM777B_F"
   },
   "outputs": [],
   "source": [
    "token = ''\n",
    "url = \"https://smartspeech.sber.ru/rest/v1/speech:recognize\"\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "audio_file_path = data.get_file_path(10)\n",
    "\n",
    "audio = AudioSegment.from_file(audio_file_path, format=\"flac\")\n",
    "\n",
    "if audio.channels == 1:\n",
    "    audio = audio.set_channels(2)\n",
    "\n",
    "if audio.frame_rate not in [8000, 16000]:\n",
    "    audio = audio.set_frame_rate(16000)\n",
    "\n",
    "audio.export(\"temp_audio.mp3\", format=\"mp3\")\n",
    "\n",
    "with open(\"temp_audio.mp3\", \"rb\") as audio_file:\n",
    "    audio_data = audio_file.read()\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'audio/mpeg',\n",
    "    'Authorization': f'Bearer {token}',\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=audio_data, verify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "BbWYiGyjmEY-"
   },
   "outputs": [],
   "source": [
    "ipd.Audio(\"temp_audio.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "wnVNuj8OvPXP"
   },
   "outputs": [],
   "source": [
    "def sber_transcribe(file_path):\n",
    "    audio = AudioSegment.from_file(file_path, format=\"flac\")\n",
    "\n",
    "    if audio.channels == 1:\n",
    "        audio = audio.set_channels(2)\n",
    "\n",
    "    if audio.frame_rate not in [8000, 16000]:\n",
    "        audio = audio.set_frame_rate(16000)\n",
    "\n",
    "    audio.export(\"temp_audio.mp3\", format=\"mp3\")\n",
    "\n",
    "    with open(\"temp_audio.mp3\", \"rb\") as audio_file:\n",
    "        audio_data = audio_file.read()\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': 'audio/mpeg',\n",
    "        'Authorization': f'Bearer {token}',\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        'language': 'ru-RU'\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=audio_data, params=params, verify=False)\n",
    "\n",
    "    return ' '.join(json.loads(response.text)['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "BT-om9ZnvI5x"
   },
   "outputs": [],
   "source": [
    "transcriptions = list()\n",
    "\n",
    "for index, row in tqdm.tqdm(df.iterrows(), total=len(df)):\n",
    "    transcription = sber_transcribe(data.get_file_path(index))\n",
    "    transcriptions.append(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "1kcK_cYGvLgW"
   },
   "outputs": [],
   "source": [
    "transcriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3W5gjweE_fNN"
   },
   "source": [
    "# Wave2vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "u-i4MWIs_g0B"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForCTC\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"jonatasgrosman/wav2vec2-large-xlsr-53-russian\")\n",
    "model = AutoModelForCTC.from_pretrained(\"jonatasgrosman/wav2vec2-large-xlsr-53-russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "60GEkubYBp9h"
   },
   "outputs": [],
   "source": [
    "def wave2vec2_transcribe(audio_file_path):\n",
    "    audio_input, sample_rate = librosa.load(audio_file_path, sr=None)\n",
    "\n",
    "    sr = 16_000\n",
    "\n",
    "    target_samples = int(len(audio_input) * sr / sample_rate)\n",
    "    resampled_audio = resample(audio_input, target_samples)\n",
    "\n",
    "    inputs = processor(resampled_audio, sampling_rate=sr, return_tensors=\"pt\").input_values\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs).logits\n",
    "\n",
    "    transcription = processor.batch_decode(logits.cpu().numpy()).text\n",
    "    return transcription[0]\n",
    "\n",
    "file_id = 2\n",
    "audio_file_path = data.get_file_path(file_id)\n",
    "transcription = wave2vec2_transcribe(audio_file_path)\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "OmrilBm1D9J_"
   },
   "outputs": [],
   "source": [
    "transcriptions = list()\n",
    "\n",
    "for index, row in tqdm.tqdm(df.iterrows(), total=len(df)):\n",
    "    transcription = wave2vec2_transcribe(data.get_file_path(index))\n",
    "    transcriptions.append(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "bD6gkW46EkWs"
   },
   "outputs": [],
   "source": [
    "transcriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZb98AakFMyl"
   },
   "source": [
    "# Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "GGL3yFewFN9b"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq\n",
    "\n",
    "processor_tiny = AutoProcessor.from_pretrained(\"openai/whisper-tiny\")\n",
    "wh_model_tiny = AutoModelForSpeechSeq2Seq.from_pretrained(\"openai/whisper-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "bwfsiYcDO63o"
   },
   "outputs": [],
   "source": [
    "processor_small = AutoProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "wh_model_small = AutoModelForSpeechSeq2Seq.from_pretrained(\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "YCd_XDK0PEQ5"
   },
   "outputs": [],
   "source": [
    "processor_large = AutoProcessor.from_pretrained(\"openai/whisper-large\")\n",
    "wh_model_large = AutoModelForSpeechSeq2Seq.from_pretrained(\"openai/whisper-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "jvHS_CmAFT5u"
   },
   "outputs": [],
   "source": [
    "def whisper_transcribe(audio_file_path, processor, model, prev_text=\"за за за. привет.\", language=\"ru\"):\n",
    "\n",
    "    audio_input, sample_rate = librosa.load(audio_file_path, sr=None)\n",
    "\n",
    "    sr = 16000\n",
    "    target_samples = int(len(audio_input) * sr / sample_rate)\n",
    "    resampled_audio = resample(audio_input, target_samples)\n",
    "\n",
    "    input_features = processor(\n",
    "        resampled_audio, sampling_rate=sr, return_tensors=\"pt\"\n",
    "    ).input_features\n",
    "\n",
    "    prompt_ids = torch.tensor(processor.get_prompt_ids(prev_text))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predicted_ids = model.generate(input_features, language=language, prompt_ids=prompt_ids)\n",
    "\n",
    "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "    return transcription[0]\n",
    "\n",
    "file_id = 1\n",
    "audio_file_path = data.get_file_path(file_id)\n",
    "transcription = whisper_transcribe(audio_file_path, language=\"ru\")\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "vcUiLjoiFZW4"
   },
   "outputs": [],
   "source": [
    "transcriptions = list()\n",
    "\n",
    "for index, row in tqdm.tqdm(labels.iterrows(), total=len(labels)):\n",
    "    transcription = whisper_transcribe(data.get_file_path(index), wh_model_tiny, processor_tiny, prev_text=row.label)\n",
    "    transcriptions.append(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "EYhvndBsPKbv"
   },
   "outputs": [],
   "source": [
    "transcriptions = list()\n",
    "\n",
    "for index, row in tqdm.tqdm(labels.iterrows(), total=len(labels)):\n",
    "    transcription = whisper_transcribe(data.get_file_path(index), wh_model_small, processor_small, prev_text=row.label)\n",
    "    transcriptions.append(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "5f-gvlliPKzs"
   },
   "outputs": [],
   "source": [
    "transcriptions = list()\n",
    "\n",
    "for index, row in tqdm.tqdm(labels.iterrows(), total=len(labels)):\n",
    "    transcription = whisper_transcribe(data.get_file_path(index), wh_model_large, processor_large, prev_text=row.label)\n",
    "    transcriptions.append(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "MkS_KyXBFb9O"
   },
   "outputs": [],
   "source": [
    "transcriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShYeLfbnGwv7"
   },
   "source": [
    "# Vosk models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "iWUtBMh5J12Q"
   },
   "outputs": [],
   "source": [
    "file_id = 10\n",
    "df.iloc[file_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7DpsJFFSGziQ"
   },
   "outputs": [],
   "source": [
    "model = Model(\"vosk-model-small-ru-0.22\")\n",
    "\n",
    "wf = AudioSegment.from_file(data.get_file_path(file_id))\n",
    "wf = wf.set_channels(1).set_frame_rate(16000)\n",
    "wf.export(\"audio.wav\", format=\"wav\")\n",
    "wf = wave.open(\"audio.wav\", \"rb\")\n",
    "\n",
    "if (wf.getnchannels() != 1\n",
    "    or wf.getsampwidth() != 2\n",
    "    or wf.getframerate() not in [8000, 16000]\n",
    "    ):\n",
    "\n",
    "    raise ValueError(\"Аудиофайл должен быть моно, 16-бит, 8кГц или 16кГц\")\n",
    "\n",
    "rec = KaldiRecognizer(model, wf.getframerate())\n",
    "\n",
    "while True:\n",
    "    d = wf.readframes(4000)\n",
    "    if len(d) == 0:\n",
    "        break\n",
    "    if rec.AcceptWaveform(d):\n",
    "        print(json.loads(rec.Result())[\"text\"])\n",
    "\n",
    "print(json.loads(rec.FinalResult())[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "k9S1EQrjJi9-"
   },
   "outputs": [],
   "source": [
    "def vosk_transcribe(file_path):\n",
    "    wf = AudioSegment.from_file(file_path)\n",
    "    wf = wf.set_channels(1).set_frame_rate(16000)\n",
    "    wf.export(\"audio.wav\", format=\"wav\")\n",
    "    wf = wave.open(\"audio.wav\", \"rb\")\n",
    "\n",
    "    if (wf.getnchannels() != 1\n",
    "        or wf.getsampwidth() != 2\n",
    "        or wf.getframerate() not in [8000, 16000]\n",
    "        ):\n",
    "\n",
    "        raise ValueError(\"Аудиофайл должен быть моно, 16-бит, 8кГц или 16кГц\")\n",
    "\n",
    "    rec = KaldiRecognizer(model, wf.getframerate())\n",
    "\n",
    "    while True:\n",
    "        d = wf.readframes(4000)\n",
    "        if len(d) == 0:\n",
    "            break\n",
    "        if rec.AcceptWaveform(d):\n",
    "            return json.loads(rec.Result())[\"text\"]\n",
    "\n",
    "    return json.loads(rec.FinalResult())[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "xv0tfx6pMM2X"
   },
   "outputs": [],
   "source": [
    "transcriptions = list()\n",
    "\n",
    "for index, row in tqdm.tqdm(df.iterrows(), total=len(df)):\n",
    "    transcription = vosk_transcribe(data.get_file_path(index))\n",
    "    transcriptions.append(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9lJ6-phGMOR5"
   },
   "outputs": [],
   "source": [
    "transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "JqfqH7djQAIO"
   },
   "outputs": [],
   "source": [
    "model = Model(\"vosk-model-ru-0.42\")\n",
    "\n",
    "wf = AudioSegment.from_file(data.get_file_path(file_id))\n",
    "wf = wf.set_channels(1).set_frame_rate(16000)\n",
    "wf.export(\"audio.wav\", format=\"wav\")\n",
    "wf = wave.open(\"audio.wav\", \"rb\")\n",
    "\n",
    "if (wf.getnchannels() != 1\n",
    "    or wf.getsampwidth() != 2\n",
    "    or wf.getframerate() not in [8000, 16000]\n",
    "    ):\n",
    "\n",
    "    raise ValueError(\"Аудиофайл должен быть моно, 16-бит, 8кГц или 16кГц\")\n",
    "\n",
    "rec = KaldiRecognizer(model, wf.getframerate())\n",
    "\n",
    "while True:\n",
    "    d = wf.readframes(4000)\n",
    "    if len(d) == 0:\n",
    "        break\n",
    "    if rec.AcceptWaveform(d):\n",
    "        print(json.loads(rec.Result())[\"text\"])\n",
    "\n",
    "print(json.loads(rec.FinalResult())[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "QJ0i9xZfQGBY"
   },
   "outputs": [],
   "source": [
    "def vosk_transcribe(file_path):\n",
    "    wf = AudioSegment.from_file(file_path)\n",
    "    wf = wf.set_channels(1).set_frame_rate(16000)\n",
    "    wf.export(\"audio.wav\", format=\"wav\")\n",
    "    wf = wave.open(\"audio.wav\", \"rb\")\n",
    "\n",
    "    if (wf.getnchannels() != 1\n",
    "        or wf.getsampwidth() != 2\n",
    "        or wf.getframerate() not in [8000, 16000]\n",
    "        ):\n",
    "\n",
    "        raise ValueError(\"Аудиофайл должен быть моно, 16-бит, 8кГц или 16кГц\")\n",
    "\n",
    "    rec = KaldiRecognizer(model, wf.getframerate())\n",
    "\n",
    "    while True:\n",
    "        d = wf.readframes(4000)\n",
    "        if len(d) == 0:\n",
    "            break\n",
    "        if rec.AcceptWaveform(d):\n",
    "            return json.loads(rec.Result())[\"text\"]\n",
    "\n",
    "    return json.loads(rec.FinalResult())[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "hF9AWe-UQGsy"
   },
   "outputs": [],
   "source": [
    "transcriptions = list()\n",
    "\n",
    "for index, row in tqdm.tqdm(df.iterrows(), total=len(df)):\n",
    "    transcription = vosk_transcribe(data.get_file_path(index))\n",
    "    transcriptions.append(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "LcknhiwaQI8v"
   },
   "outputs": [],
   "source": [
    "transcriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGNl9yUV1P0_"
   },
   "source": [
    "# Google API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "hXl_dfEeuq1Y"
   },
   "outputs": [],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "CnZ3Mta_0LQd"
   },
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "O6a7aZRfzpMG"
   },
   "outputs": [],
   "source": [
    "def google_transcribe(audio_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    try:\n",
    "        # Загрузка аудиофайла\n",
    "        with sr.AudioFile(audio_path) as source:\n",
    "            audio_data = recognizer.record(source)\n",
    "        # Расшифровка речи с использованием Google Speech API\n",
    "        text = recognizer.recognize_google(audio_data, language='ru-RU')  # Измените 'ru-RU' на нужный язык\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Не удалось распознать речь.\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Ошибка запроса к сервису распознавания: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "sLHk2xTx0IWV"
   },
   "outputs": [],
   "source": [
    "google_transcribe(data.get_file_path(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "5vChEe6V0V_b"
   },
   "outputs": [],
   "source": [
    "transcriptions = list()\n",
    "\n",
    "for index, row in tqdm.tqdm(df.iterrows(), total=len(df)):\n",
    "    transcription = google_transcribe(data.get_file_path(index))\n",
    "    transcriptions.append(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "O2G7UiCJ0ZE9"
   },
   "outputs": [],
   "source": [
    "transcriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yd5HvSvpAf-k"
   },
   "source": [
    "# Whisper API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "euXZg77YB8sT"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "iOGJrXPMAiAa"
   },
   "outputs": [],
   "source": [
    "# todo: delete API key\n",
    "client = OpenAI(api_key='')\n",
    "\n",
    "def whisperAPI_transcribe(file_path, prompt):\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as audio_file:\n",
    "            response = client.audio.transcriptions.create(\n",
    "                model=\"whisper-1\",\n",
    "                file=audio_file,\n",
    "                prompt=prompt,\n",
    "                language=\"ru\"\n",
    "            )\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error during transcription: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "AkfBQlb4BiTi"
   },
   "outputs": [],
   "source": [
    "file_id = 1\n",
    "audio_file_path = data.get_file_path(file_id)\n",
    "transcription = whisperAPI_transcribe(audio_file_path, \"За за за. Привет. Катя\")\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "PFcWYAdcCKjC"
   },
   "outputs": [],
   "source": [
    "transcriptions = list()\n",
    "\n",
    "for index, row in tqdm.tqdm(labels.iterrows(), total=len(labels)):\n",
    "    transcription = whisperAPI_transcribe(data.get_file_path(index), prompt=row.label)\n",
    "    transcriptions.append(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "uxJTcLq_DB_c"
   },
   "outputs": [],
   "source": [
    "transcriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSyq68tu42e_"
   },
   "source": [
    "# Yandex SpeechKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ouFwZi7p9Uaj"
   },
   "outputs": [],
   "source": [
    "# todo: delete API key\n",
    "api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "iGZyCAp7-du0"
   },
   "outputs": [],
   "source": [
    "def convert_flac_to_lpcm(input_path, output_path):\n",
    "    audio = AudioSegment.from_file(input_path, format=\"flac\")\n",
    "    audio = audio.set_frame_rate(16000).set_channels(1).set_sample_width(2)\n",
    "    raw_data = audio.raw_data\n",
    "\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "rNx_ft4U44u5"
   },
   "outputs": [],
   "source": [
    "url = 'https://stt.api.cloud.yandex.net/speech/v1/stt:recognize?lang=ru-RU&topic=general&format=lpcm&sampleRateHertz=16000'\n",
    "audio_file_path = data.get_file_path(10)\n",
    "\n",
    "convert_flac_to_lpcm(audio_file_path, \"tmp.lpcm\")\n",
    "\n",
    "with open(\"tmp.lpcm\", \"rb\") as audio_file:\n",
    "    audio_data = audio_file.read()\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'Api-Key {api_key}',\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=audio_data, verify=False)\n",
    "res = response\n",
    "' '.join(json.loads(response.text)['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "AuB-I31bmT0F"
   },
   "outputs": [],
   "source": [
    "ipd.Audio('tmp.lpcm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "a9Pr51YiuQOC"
   },
   "outputs": [],
   "source": [
    "def yandex_transcribe(file_path):\n",
    "    convert_flac_to_lpcm(file_path, \"tmp.lpcm\")\n",
    "\n",
    "    with open(\"tmp.lpcm\", \"rb\") as audio_file:\n",
    "        audio_data = audio_file.read()\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': f'Api-Key {api_key}',\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=audio_data, verify=False)\n",
    "    return json.loads(response.text)['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Wjof8E-puJ_s"
   },
   "outputs": [],
   "source": [
    "yandex_transcribe(audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ntXAxRkxuqpt"
   },
   "outputs": [],
   "source": [
    "transcriptions = list()\n",
    "\n",
    "for index, row in tqdm.tqdm(labels.iterrows(), total=len(labels)):\n",
    "    transcription = yandex_transcribe(data.get_file_path(index))\n",
    "    transcriptions.append(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ZQdsiw6kut_1"
   },
   "outputs": [],
   "source": [
    "transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "YsMOd21du9x2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "-C395b2T38Nh",
    "3W5gjweE_fNN",
    "BZb98AakFMyl",
    "ShYeLfbnGwv7",
    "mGNl9yUV1P0_"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
